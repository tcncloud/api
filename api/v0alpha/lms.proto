syntax = "proto3";

package api.v0alpha;

import "annotations/authz.proto";
import "api/commons/communication.proto";
import "api/commons/compliance.proto";
import "api/commons/lms.proto";
import "api/commons/perms.proto";
import "api/commons/types.proto";
import "google/api/annotations.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/empty.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/wrappers.proto";

service LMS {
  rpc GetPublicKey(GetPublicKeyReq) returns (PublicKey) {
    option (google.api.http).post = "/api/v0alpha/lms/pgpkey/get";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc CreateFileTemplate(FileTemplate) returns (FileTemplate) {
    option (google.api.http).post = "/api/v0alpha/lms/file_templates/create";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc ListFileTemplates(GetFileTemplatesReq) returns (stream FileTemplate) {
    option (google.api.http).post = "/api/v0alpha/lms/file_templates";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc UpdateFileTemplate(FileTemplate) returns (FileTemplate) {
    option (google.api.http).post = "/api/v0alpha/lms/file_templates/update";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc DeleteFileTemplate(FileTemplate) returns (FileTemplate) {
    option (google.api.http).post = "/api/v0alpha/lms/file_templates/delete";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc GetFileTemplate(FileTemplate) returns (FileTemplate) {
    option (google.api.http).post = "/api/v0alpha/lms/file_templates/get";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  rpc CreateField(Field) returns (Field) {
    option (google.api.http).post = "/api/v0alpha/lms/fields/create";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc ListFields(ListFieldsReq) returns (Fields) {
    option (google.api.http).post = "/api/v0alpha/lms/fields";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc GetField(Field) returns (Field) {
    option (google.api.http).post = "/api/v0alpha/lms/fields/get";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc UpdateField(UpdateFieldReq) returns (Field) {
    option (google.api.http).post = "/api/v0alpha/lms/fields/update";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc DeleteField(Field) returns (Field) {
    option (google.api.http).delete = "/api/v0alpha/lms/fields/delete";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc ListAvailableFieldsByElementId(ListAvailableFieldsByElementIdReq) returns (ProcessFields) {
    option (google.api.http).post = "/api/v0alpha/lms/fieldsbyelement";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc ListFieldsForElement(ListFieldsForElementReq) returns (ListFieldsForElementRes) {
    option (google.api.http).post = "/api/v0alpha/lms/fieldsforelement";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }

  rpc ListAutocompleteFields(ListAutocompleteFieldsReq) returns (ListAutocompleteFieldsRes) {
    option (google.api.http).post = "/api/v0alpha/lms/autocompletefields";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }

  // list campaign links and descriptions
  rpc ListCampaignLinks(google.protobuf.Empty) returns (ListCampaignLinksRes) {
    option (google.api.http).post = "/api/v0alpha/lms/campaignlink/list";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_ORG_VIEW]
        }
      ];
    };
  }

  rpc PeekList(PeekListReq) returns (PeekListRes) {
    option (google.api.http).post = "/api/v0alpha/lms/lists/preview";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc GetHistory(GetHistoryReq) returns (GetHistoryRes) {
    option (google.api.http).post = "/api/v0alpha/lms/lists/history";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc CreateElement(Element) returns (Element) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines/create";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc ListElements(ListElementsReq) returns (stream Element) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc GetElement(ElementPK) returns (Element) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines/get";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc UpdateElement(Element) returns (Element) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines/update";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc DeleteElement(Element) returns (Element) {
    option (google.api.http).delete = "/api/v0alpha/lms/pipelines/delete";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  // CopyPipelineUpstream copies an Element and all of its' parents
  rpc CopyPipelineUpstream(Element) returns (stream Element) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines/copyupstream";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  // CopyPipelineDownstream copies an Element and all of its' children
  rpc CopyPipelineDownstream(Element) returns (stream Element) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines/copydownstream";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc ProcessElement(ProcessElementReq) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/pipelines/process";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }
  rpc GetAvailableFields(google.protobuf.Empty) returns (ProcessFields) {
    option (google.api.http).post = "/api/v0alpha/lms/available-fields";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  // returns queue events for the last 30 minutes
  rpc ListNewEvents(google.protobuf.Empty) returns (Events) {
    option (google.api.http).post = "/api/v0alpha/lms/get-new-events";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc ViewQueue(ViewQueueReq) returns (Events) {
    option (google.api.http).post = "/api/v0alpha/lms/view-queue";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc Autocomplete(ParseReq) returns (ParseRes) {
    option (google.api.http).post = "/api/v0alpha/lms/autocomplete";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }

  rpc GetComplianceScrubLists(GetComplianceScrubListsReq) returns (GetComplianceScrubListsRes) {
    option (google.api.http).post = "/api/v0alpha/lms/compliancescrublists";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  rpc FindFieldUsages(FindFieldUsagesReq) returns (FindFieldUsagesRes) {
    option (google.api.http).post = "/api/v0alpha/lms/find-field-usages";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  rpc FindInvalidElements(FindInvalidElementsReq) returns (FindInvalidElementsRes) {
    option (google.api.http).post = "/api/v0alpha/lms/find-invalid-elements";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  /* CJS calls */
  rpc CreateCollection(CollectionMetadata) returns (CollectionMetadata) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/create";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }
  rpc GetCollection(GetCollectionReq) returns (CollectionMetadata) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/get";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc UpdateCollection(CollectionMetadata) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/update";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }
  rpc DeleteCollection(DeleteCollectionReq) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/delete";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }
  rpc ListCollections(ListCollectionsReq) returns (ListCollectionsRes) {
    option (google.api.http).post = "/api/v0alpha/lms/collections";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
  rpc ResetCollection(ResetCollectionReq) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/reset";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  rpc AddCollectionEntry(CollectionEntry) returns (CollectionEntry) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/add-entry";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }
  rpc DeleteCollectionEntry(DeleteCollectionEntryReq) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/delete-entry";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }
  rpc UpdateCollectionEntry(CollectionEntry) returns (CollectionEntry) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/update-entry";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // StreamCollection needs to be used in conjunction with GetCollection
  // to have the metadata associated with it
  rpc StreamCollection(StreamCollectionReq) returns (stream CollectionEntry) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/stream";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // SearchCollectionsWithQueryPaginated needs to be used in conjunction with GetCollection
  // to have the metadata associated with it
  rpc SearchCollectionsPaginated(SearchCollectionsPaginatedReq) returns (PaginatedSearchRes) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/searchcollections";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // GetCollectionEntries fetches a page (size specified by the page_size param) of entries for
  // the specified collection_id, org_id, region_id starting at location specified by from
  rpc GetCollectionEntries(GetCollectionEntriesReq) returns (GetCollectionEntriesRes) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/getcollectionentries";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }

  // CreateCjsSearchDefinition creates a search definition
  rpc CreateCjsSearchDefinition(CjsSearchDefinition) returns (CjsSearchDefinition) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/createsearchdefinition";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // GetCjsSearchDefinition gets the search definition specified by search_definition_id
  rpc GetCjsSearchDefinition(GetCjsSearchDefinitionReq) returns (CjsSearchDefinition) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/getsearchdefinition";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // UpdateCjsSearchDefinition updates the search definition specified by search_definition_id
  rpc UpdateCjsSearchDefinition(CjsSearchDefinition) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/updatesearchdefinition";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // DeleteCjsSearchDefinition deletes the search definition specified by search_definition_id
  rpc DeleteCjsSearchDefinition(DeleteCjsSearchDefinitionReq) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/deletesearchdefinition";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // ListCjsSearchDefinitions lists the search definitions
  rpc ListCjsSearchDefinitions(ListCjsSearchDefinitionsReq) returns (ListCjsSearchDefinitionsRes) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/listsearchdefinitions";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // ExecuteCjsSearchDefinition executes the search definition specified by search_definition_id
  rpc ExecuteCjsSearchDefinition(ExecuteCjsSearchDefinitionReq) returns (ExecuteCjsSearchDefinitionRes) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/executesearchdefinition";
    option (google.api.http).body = "*";
    option (annotations.authz) = {no_permissions: true};
  }

  // GetCjsSecureSearchCriteria gets the secure search criteria
  rpc GetCjsSecureSearchCriteria(GetCjsSecureSearchCriteriaReq) returns (CjsSecureSearchCriteria) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/getsecuresearchdcriteria";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  // CreateCjsSecureSearchCriteria creates a secure search criteria
  rpc CreateCjsSecureSearchCriteria(CjsSecureSearchCriteria) returns (CjsSecureSearchCriteria) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/createsecuresearchdcriteria";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  // UpdateCjsSecureSearchCriteria updates the secure search criteria
  rpc UpdateCjsSecureSearchCriteria(CjsSecureSearchCriteria) returns (google.protobuf.Empty) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/updatesecuresearchdcriteria";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_EDIT]
        }
      ];
    };
  }

  rpc GetQueuedEventsStatusByElementId(ElementPK) returns (Events) {
    option (google.api.http).post = "/api/v0alpha/lms/collections/getqueuedeventsstatusbyelementid";
    option (google.api.http).body = "*";
    option (annotations.authz) = {
      sets: [
        {
          permissions: [PERMISSION_LMS_VIEW]
        }
      ];
    };
  }
}

message GetPublicKeyReq {}
message PublicKey {
  string key = 1;
}

message FindFieldUsagesReq {
  string field_name = 3;
}
message NameAndId {
  string id = 1;
  string name = 2;
}
message FindFieldUsagesRes {
  string field_name = 1;
  // contains the name, and id of all the file templates that use field_name.
  repeated NameAndId file_templates = 2;
  // contains the name, and id of all the elements that use field_name
  repeated NameAndId elements = 3;
}

message ElementError {
  message InvalidExpression {
    string expression = 1;
  }
  message MissingField {
    string field_name = 2;
  }
  // this element is doing an operation that will always fail.
  // Examples:
  //   - Enrichment with fields that are not phone or zip type
  //   - reshape Add/Subtract functions on non number types
  //   - Filter using datetime math with non datetime fields
  // this will be possible to determine all cases after https://git.tcncloud.net/m/neo/-/issues/6924
  message BadFieldType {
    string field_name = 3;
  }
  // an ElementError contains a "reason" the element is invalid that is one of the above types
  oneof reason {
    InvalidExpression invalid_expression = 4;
    MissingField missing_field = 5;
    BadFieldType bad_field_type = 6;
  }
}
message ElementSummary {
  string element_id = 1;
  string element_name = 2;
  ElementError error = 3;
}
message FindInvalidElementsReq {
  string org_id = 1;
  string region_id = 2;
}
message FindInvalidElementsRes {
  repeated ElementSummary invalid_elements = 1;
}

message GetComplianceScrubListsReq {}
message GetComplianceScrubListsRes {
  repeated string scrub_lists = 1;
}

message ProcessElementReq {
  string element_id = 1;
}

message ListAvailableFieldsByElementIdReq {
  string element_id = 1;
}
message ListFieldsForElementReq {
  string element_id = 1;
}
message ListFieldsForElementRes {
  repeated Field fields = 1;
}
message ListAutocompleteFieldsReq {}
message ListAutocompleteFieldsRes {
  repeated Field fields = 1;
}
message ElementPK {
  string element_id = 1;
}

// REPLACES PipelineElement and List
message Element {
  string element_id = 3;

  string name = 10;
  repeated string inputs = 11;
  repeated bool input_is_discard = 20;

  Process transform = 13;
  api.commons.PipelineElementStatusType last_status = 14;
  repeated string labels = 16;
  google.protobuf.Timestamp created_date = 17;
  google.protobuf.Timestamp last_edited = 18;
  string description = 19;
}

message PeekListReq {
  string element_id = 3;
  int64 version = 4;

  int32 page_size = 10;
  int32 page = 12;

  // process to run before we return the records back
  // currently only expecting this to be a simple filter process
  Process process = 13;
  // if true, we will fetch the discards chunk to look at instead of the data chunk
  bool peek_at_discards = 14;
}
message PeekListRes {
  repeated RecordProto records = 1;
  ListMetrics metrics = 2;
}

message GetHistoryReq {
  string element_id = 3;

  int32 count = 10;
  int64 starting_id = 11;
}

message GetHistoryRes {
  string element_id = 3;
  repeated HistoryAndCount commits = 11;
}

// the history table stores history for pipeline_elements
message History {
  string element_id = 3;
  int64 history_id = 4;
  Process process = 7;
  // whether the pipeline process was successful, or a failure.  Success = false
  bool failed = 10;
  int32 attempt_number = 12;

  google.protobuf.StringValue reason = 13;
  google.protobuf.Timestamp upload_ts = 14;
  google.protobuf.Timestamp started_ts = 15;
  google.protobuf.Timestamp finished_ts = 16;

  // will only match a valid event in the event queue as long as it isn't
  // emptied
  int64 event_id = 18;
  string parent_element_id = 22;
  ListMetrics metrics = 23;
  ListMetrics discard_metrics = 24;
}

// since its possible to get a load of history events that all look the same
// this keeps track of the range. history_id and ending_history_id
// are the range of data where 'failed', and 'reason' were the same.
// The rest of the fields point to the history_id's record
// 'count' is the field that keeps track of how many messages in a row were
// similar
message HistoryAndCount {
  string element_id = 3;
  // history_id of the element that started getting the duplicate error message
  int64 history_id = 4;
  // history_id of where we stopped getting the duplicate error message
  int64 ending_history_id = 5;
  Process process = 7;
  // whether the pipeline process was successful, or a failure.  Success = false
  bool failed = 10;
  int32 attempt_number = 12;

  google.protobuf.StringValue reason = 13;
  google.protobuf.Timestamp upload_ts = 14;
  google.protobuf.Timestamp started_ts = 15;
  google.protobuf.Timestamp finished_ts = 16;

  // will only match a valid event in the event queue as long as it isn't
  // emptied
  int64 event_id = 18;
  string parent_element_id = 22;
  ListMetrics metrics = 23;
  ListMetrics discard_metrics = 25;
  // how many messages encountered a similar 'reason' field
  int64 count = 24;
}

message RecordProto {
  repeated RecordFieldProto fields = 1;
}

message RecordProtoPair {
  RecordProto old = 1;
  RecordProto new = 2;
}

message ProcessFields {
  message NestedField {
    string name = 1;
    api.commons.RecordType field_type = 2;
  }
  message Field {
    string name = 3;
    api.commons.RecordType field_type = 4;
    // any nested fields, could be empty
    repeated NestedField nested = 5;
    string format = 9;
  }

  repeated Field fields = 8;
}

message FieldPK {
  string name = 3;
}

message Field {
  string name = 3;
  api.commons.FieldType type = 4;
  google.protobuf.Timestamp date_modified = 5;
  FieldMetadata metadata = 10;
  string description = 11;
}

message UpdateFieldReq {
  string name = 3;
  api.commons.FieldType type = 4;
  google.protobuf.Timestamp date_modified = 5;
  string new_name = 6;
  FieldMetadata metadata = 10;
  string description = 11;
}

message FieldMetadata {
  string time_format = 1;
  api.commons.DateTimePrecision precision = 2;

  // 3-10 are Parsing Options
  // Remove any characters that are in this string
  // `remove_characters` will override leave_characters
  string remove_characters = 3;
  // If the parsed value is empty
  // it will be replaced with this value
  string replace_empty = 4;
  // If an error is encountered with parsing
  // then the field will be replaced with this value
  string replace_error = 5;
  // Remove any letters (a-zA-Z) from the field
  bool remove_letters = 6;
  // Remove any numbers (digits 0-9) from the field
  bool remove_numbers = 7;
  // Removes any symbols or punctuation from the field
  bool remove_symbols = 8;
  // Any characters in this string will not be remove
  // can be overridden by remove_characters
  string leave_characters = 9;
  // Remove any matches of this entire string
  string remove_string = 10;
  // following fields are for json file format types:
  // represents a field that can be fetched from a json payload
  // the type will match whatever is at the end of the 'json_dot_path' field
  // when we use the 'json_dot_path' to retrieve from a json payload.
  // so to get a primitive type (string, number, bool), you must have that value at the end of the dot_path
  // null is treated as empty string.
  // In the case of complex types, we are expecting
  // a json object with names and types that match one of our payloads
  // ie: postal code would be {postalCode: "84790"}
  // 'json_force_type_match' can be set to force the results to be a type, or error.
  // In this case, the result value needs to either be the matching type, or a string, where it will be parsed.

  // 'json_dot_path' holds the json path that will fetch the  value for this field by walking path
  // over a json object via:
  // https://github.com/tidwall/gjson
  // ex: dot_path = a.b.0.firstName
  // Values must resolve to one thing, not a range of things. If a range is retrieved, the first value is taken
  // the rest are ignored.
  // If string is empty, we just use the field name for the path
  string json_dot_path = 11;
  // If true value retrieved from json *must* match the field definition, or error.
  // If true, the value if a string, will be 'parsed' into the correct type.
  // If false, the value will be used as is, meaning time_strings, number_strings and the like will remain as strings.
  bool json_force_type_match = 12;
  // for fixed width files indicates the starting position of the data.
  // if it is -1, starting position is one character after the previous fields starting position + length.
  // if this is the first field and it is -1, starting position is 0
  int32 starting_position = 13;
  // for fixed width files indicates how many characters to the right of starting position we will read.
  // this field is required to be greater than 0.
  int32 field_length = 14;
}

message Fields {
  repeated Field fields = 1;
}

// first value is the field_name in the record.
// additional values are nested fields on record field looked up from index[0]
message FieldIndex {
  repeated string index = 1;
  // modify the fetched field, if the fetched field's type
  // can support the modifier
  oneof modifier {
    // modifies the fetched field if it is a datetime field
    DateTimeModifier datetime = 2;
  }
}

message ListFieldsReq {}

message RecordFieldProto {
  string name = 1;
  oneof payload {
    string string_value = 2;
    double number_value = 3;
    bool bool_value = 4;
    Phone phone = 5;
    Currency currency = 6;
    PostalCode postal_code = 8;
    Email email = 9;
    DateTime date_time = 10;
    RepeatedRecords repeated_records = 13;
    RecordFieldMap record_field_map = 14;
    Error err = 15;
    EnrichedPhone enriched_phone = 16;
    EnrichedZip enriched_zip = 17;
  }
}
message RepeatedRecords {
  repeated RecordProto records = 1;
}

message ListElementsReq {
  repeated string labels = 1;
}
message GetFileTemplatesReq {}

message FileTemplateField {
  string name = 1;
  api.commons.FieldType type = 2;
}

message FileTemplateFields {
  repeated FileTemplateField fields = 1;
}

message FieldTypes {
  repeated api.commons.FieldType values = 1;
}

message FileTemplate {
  string file_template_id = 3;
  string name = 10;
  string description = 11;
  repeated string field_names = 12;
  FileFormatParams file_format_params = 14;
  api.commons.FileFormat file_format = 15;
  repeated Field fields = 16;
}

message LMSUploadReq {
  string element_id = 3;
  // if left empty, will use the list_id's default file template
  string file_id = 12;
}

message LMSUploadRes {}

message ReRunReq {
  string list_id = 3;
  string rerun_url = 4;
}
message ReRunRes {}

message Process {
  string expression = 55;
  oneof proc {
    AppendProcess append = 30;
    SortCriteria sort = 31;
    FilterProcess filter = 32;
    GSExportProcess gs_export = 42;
    P3ExportProcess p3_export = 44;
    // USE LookupProcess
    ComplProcess compl = 45 [deprecated = true];
    DeDupCriteria dedup = 46;
    CFSExportProcess cfs_export = 47;
    SftpExportProcess sftp_export = 48;
    ReshapeProcess reshape = 49;
    LookupProcess lookup = 50;
    // split into ApiEntrypoint and SftpImport
    EntrypointProcess entrypoint = 51 [deprecated = true];
    ComplianceExportProcess compliance_export = 52;
    ApiEntrypoint api_entrypoint = 53;
    SftpImport sftp_import = 54;
    ScrubProcess scrub = 56;
    FrequencyProcess frequency = 57;
    // Will import a list from Durable Data Service(CJS)
    // The templates for CJS and LMS will need to match
    CjsImportProcess cjs_import = 58;
    // Exports a list to Durable Data Service (CJS)
    // The exported fields will need to match the
    // CJS template if exporting to an existing list.
    CjsExportProcess cjs_export = 59;
    // Enriches an LMS list with
    // data from a CJS list
    CjsEnrichmentProcess cjs_enrich = 60;
    WebEntrypointProcess web_entrypoint = 61;
    DeleteScrubEntriesProcess delete_scrub_entries = 62;
    WfmExportProcess wfm_export = 63;
    PaymentLinkEnrichment link_enrich = 64 [deprecated = true];
    RndEnrichmentProcess rnd = 65;
    // Enriches an LMS list with consent data
    ConsentEnrichmentProcess consent_enrich = 66;
    // Exchanges with compliance consent to add or delete consents
    ConsentExportProcess consent_export = 67;
    // Processes a list through compliance and enriching
    // whether a coule would have been permitted or not
    ComplianceProcessor compliance_processor = 69;
    ConsentEntrypointProcess consent_entrypoint = 70;
    PortalLinkEnrichment portal_link_enrich = 71;
    BulkWebEntrypointProcess bulk_web_entrypoint = 72;
    // OmniExchangeProcess allows omni to import contacts using LMS file upload
    OmniExchangeProcess omni_exchange_process = 73;
    // WebExchangeProcess allows a user to setup a process to send data to an external api
    WebExchangeProcess web_exchange_process = 74;
    SplitCriteria split = 75;
  }
}

message ComplianceProcessor {
  // ID for the rulset to run against
  string rule_set_id = 1;
  // Comm type we are using (phone, email, sms)
  api.commons.CommType comm_type = 5;
  // call type we are checking (inbound, outbound, preview, mac)
  // or field containing the call type
  string call_type = 6;
  // Field containing the phone number (optional)
  string phone_number_field = 7;
  // Field containing the email (optional)
  string email_field = 8;
  // Field containing the zip code
  string zip_code_field = 9;
  // The Key is the metadata field name
  // The value is the record field that
  // contains the value
  map<string, string> call_metadata = 10;
  // Country code, or field containing
  // the country code
  string country_code = 11;
}

// sources the LMS list with consent records
message ConsentEntrypointProcess {
  // Profile Id to get consent records from
  string consent_profile_id = 1;
}

message ConsentEnrichmentProcess {
  // Specifies which record field contains the content
  string content_field = 3;
  // Profile to use
  string consent_profile = 4;
  // Profile Id
  string consent_profile_id = 5;
}

message ConsentExportProcess {
  // Specifies which record field is the content
  string content_field = 3;
  // Profile to use
  string consent_profile = 4;
  // Profile ID of profile to use
  string consent_profile_id = 5; // Optional, only needed with phone/sms
  // Run as test, disabled, or normal
  api.commons.RunType run_type = 6;
  // Type of consent action to do: ADD/REVOKE
  api.commons.ConsentActionType action = 7;
  // Field name or literal value for referring url when creating consent
  string referring_url = 8;
  // Field name or literal value for topic when creating consent
  string topic = 9;
  // Field name or literal value for revoked reason when creating consent
  string revoked_reason = 10;
  // Field name or literal value for granted reason when creating consent
  string granted_reason = 11;
  // Field name or literal value for proof when creating consent
  string proof = 12;
  // Field name or literal value for "condition time of day from" when creating consent
  string condition_time_of_day_from = 13;
  // Field name or literal value for "condition time of day to" when creating consent
  string condition_time_of_day_to = 14;
  // Field name or literal value for notes when creating consent
  string notes = 15;
  // Field name for expire timestamp when creating consent
  // replaced by expiration
  string expire = 16 [deprecated = true];
  // Field name for "condition from" timestamp when creating consent
  string condition_from = 17;
  // Field name for "condition to" timestamp when creating consent
  string condition_to = 18;
  // Either a field name or content type value for the contennt type of the content
  oneof content_type {
    api.commons.ContentType content_type_val = 27;
    string content_type_field_name = 28;
  }
  // Either a field name or channel type value for the channel type. Field value should be a string
  oneof channel_type {
    api.commons.Channel channel_type_val = 29;
    string channel_type_field_name = 30;
  }
  oneof expiration {
    // the static time that consent will expire at
    google.protobuf.Timestamp expiration_date = 31;
    // the field name that holds info about the static time consent will expire at
    string expiration_field_name = 32;
    // the relative time consent will expire at
    google.protobuf.Duration expiration_after_duration = 33;
  }
}

message PaymentLinkEnrichment {
  repeated string fields = 1 [deprecated = true];
  string payment_link_config_id = 2 [deprecated = true];
  // if true, we will not generate a link for lms records that to not contain *all* of the fields.
  // instead we will move that record to the discards
  bool discard_on_missing_fields = 3 [deprecated = true];
  // lms field names as keys, mapped to what they should be called in the portal
  map<string, string> key_map = 4;
  // the portal that these links will belong to.
  string portal_id = 5;
}
message PortalLinkEnrichment {
  // lms field names as keys, mapped to what they should be called in the portal
  map<string, string> key_map = 1;
  // the portal that these links will belong to.
  string portal_id = 2;
  // unit type and quantity of: months, weeks, days, hours
  Expiration expiration = 6;
  // if the payment will process or not
  bool demo = 7;
}

message Expiration {
  // units can be weeks, days, or hours
  TimeUnit units = 1;
  // max 1 year
  int64 quantity = 2;
}

enum TimeUnit {
  //DEFAULT is decided by SURL (no quantity needed)
  DEFAULT = 0;
  TIME_WEEKS = 1;
  TIME_DAYS = 2;
  TIME_HOURS = 3;
}

// split into ApiEntrypoint and SftpImport
message EntrypointProcess {}
message ApiEntrypoint {
  string fts_id = 100;
  // prefered/default template
  string file_template_id = 16;
  bool incremental = 17;
  bool encrypted = 18;
}

// HttpReq is what we will use to construct a GET or POST request to the server.
message HttpReq {
  // what url to hit. First url in the group Must be able to be used as is, it
  // won't be parsed or messed with. Just passed directly to an http client.
  // every additional url instead of being a simple string can use values
  // retrieved from the previous response body, or headers. Examples: url =
  // "https://{{header.nextUrl}}" url = "{{body.path.toThe.1.nextUrl}}/search?
  // country={{body.country}}" to restate in english the examples: we will
  // replace the contents between {{ }} with the values retrieved from the
  // previous response body or headers the last url must always contain records
  // that can be parsed by the specified file template. templated values must
  // always be:
  // - wrapped in {{ }},
  // - first word be either "header." or "body."
  //   followed by a json dot path to the value to be looked up, or
  // - a named starting with $ ex. {{$token}} referencing a previous saved value.
  // - a special field: <TODAY> <NOW>  <TODAY.UNIX>
  // if one of these template values is found, it is assumed the previous
  // response is json, otherwise the lookups will fail, and the entrypoint will
  // error.
  string url = 1;
  // initial headers must have static values for all the key value pairs.
  // every headers field after the first can contain template wrappers to
  // specify looking up the value from the previous response body, or headers
  // example:
  // { "key": "value", "{{header.nextKey}}": "{{body.somePath.to.a.str}}"}
  map<string, string> headers = 2;
  // same as url, and headers fields, it is possible to use templated values to
  // construct the body often, body is either empty, or a json string
  string body = 3;
  // what type of request to make  GET by default
  api.commons.HttpVerb method = 4;
  // the values to save from this response.
  // saved values can be referenced on *all* future requests.
  // so things like auth tokens need to be declared here so they can be
  // referenced by name later.
  // ex:
  // putting { "token": "body.response.authToken" } in the map
  // will allow us to use {{$token}} in all future http requests
  map<string, string> named_response_values = 5;
}
message WebEntrypointProcess {
  // the requests to make, in order, to get to our records.
  // Last request in the array must always be able to be parsed by the file template, or the template represented by the file_template_id
  // a nil, or 0 length array for http_requests will fail the entrypoint.
  // See comments on the HttpReq message for using templated values in the requests.
  repeated HttpReq http_requests = 1;
  string file_template_id = 5;
  // if set, the process will use this exact template during processing
  FileTemplate file_template = 6;
  // The name of this process. -YYYYMMDD will be attached.
  // If empty, defaults to web-entrypoint-<now>.
  // If scheduled through the lms-api, the element name will be used if left blank
  string name = 7;
  // the cron string, just like sftp_import process
  string cron = 19;
  // Specifies the timezone to be used by the cron
  string timezone = 20;
  // if false, the cron will not put events int he queue when triggered
  bool enabled = 21;
}

// BulkWebEntrypointProcess works like a WebEntrypointProcess, but allows
// user to specify a paginated request that is repeated till there are no
// more records to import. This should be used when we don't know how much
// data we are importing, or if we have a long running
message BulkWebEntrypointProcess {
  // the requests to make, in order, to access priliminary data needed
  // to make the bulk data action part of the entrypoint.
  // the user is expected to specify which values need to be saved
  // in the HttpReq.named_response_values map.
  repeated HttpReq preliminary_requests = 2;

  // this request is expected to return records that can be parsed by
  // the file template each time it is called.
  // if no termination case is specified, then we terminate after the first run.
  PaginatedHttpRequest paginated_request = 4;

  // the file template that can parse the paginated data
  string file_template_id = 5;
  // The name of this process. -YYYYMMDD will be attached.
  // If empty, defaults to web-entrypoint-<now>.
  // If scheduled through the lms-api, the element name will be used if left
  // blank
  string name = 7;
  // the cron string, just like sftp_import process
  string cron = 19;
  // Specifies the timezone to be used by the cron
  string timezone = 20;
  // if false, the cron will not put events in the queue when triggered
  bool enabled = 21;
  // how many pages we should save before aggregating the data and sending downstream
  // default is 100. Max is 10000.
  // If a termination state hasn't been reached, the event will be re-queued and continue
  // where it left off.
  int64 flush_page_count = 22;
  // how much total elapsed time (in minutes) we want to wait before flushing records.
  // if total time spent aggregating the data goes over this many minutes, we will flush
  // the current records downstream.
  // default is 20. Max is 120. Min is 1.
  // If a termination state hasn't been reached, the event will be re-queued and continue
  // where it left off.
  int64 flush_minute_count = 23;
  // if true, we will switch to processing mode when we have enough records to flush
  // even if we haven't downloaded all the pages yet.
  // after the current records are flushed, we switch back to downloading the remaining records.
  // If false (default), we download all the pages before we start processing any records.
  bool flush_during_check = 24;
}

// OmniExchangeProcess allows omni to import contacts using LMS file upload
message OmniExchangeProcess {
  reserved 3;
  // project_id is the id for the Omni project
  int64 project_id = 1 [jstype = JS_STRING];
  // campaign_id is the id for the Omni campaign
  int64 campaign_id = 2 [jstype = JS_STRING];
  string time_zone = 5;
  //the number of days into the future, can be 0
  int64 days = 4;
  // hour of the day, 0-23
  int64 hour = 6;
  // minute of the hour, 0-59
  int64 minute = 7;
}

// WebExchangeProcess is an lms exchange process that lets the user upload data to third part api.
// right now rest is supported with non bulk uploads.
message WebExchangeProcess {
  repeated HttpReq http_requests = 1;
  // threshold for a failed process. if threshold is exceeded, entire process fails
  int64 error_threshold = 2;
}

// this request is expected to return records that can be parsed by
// the file template each time it is called.
// if no termination case is specified, (end_for_any, and end_for_all are empty)
// then we terminate after the first call.
message PaginatedHttpRequest {
  // an http request that must return records.
  // the iteration_request will have access to the special template variable
  // {{$i}} which will increment by 1 every time the request is made.
  HttpReq iteration_request = 1;
  // the starting value of i.
  int64 start_index = 2;
  // terminates if *any* of the terminators return true
  repeated api.commons.PaginationTerminator end_for_any = 3;
  // terminates if all fo the terminators return true
  repeated api.commons.PaginationTerminator end_for_all = 4;
  // if set, and if the PaginationTerminator returns true
  // the response is considered not done.
  // No rows are expected to be imported from this response,
  // and the request will retry.
  api.commons.PaginationTerminator request_not_ready = 5;
  // how many seconds we will wait before retrying if request_not_ready returns true
  int64 not_ready_wait_seconds = 6;
  // whether to retry the preliminary when we get a not ready state
  bool not_ready_redo_preliminary = 7;
  // if set we do not advance {{$i}} to the next value if request_not_ready returns true
  bool not_ready_skip_iteration = 8;
  // whether the end page has records on it
  bool process_stop_page = 9;
}

// Takes SFTP credentials and import a file
message SftpImport {
  // SFTP credentials. `password` will
  // be tried first for authentication,
  // if left blank, `private_key` will be tried.
  string user = 4;
  string password = 5;
  string private_key = 6;
  string address = 7;
  string port = 8;

  api.commons.FilePattern file_pattern = 13;

  // We will only process if enabled
  bool enabled = 15;
  // prefered/default template
  string file_template_id = 16;
  bool incremental = 17;
  // Specifies whether the files to be imported
  // are encrypted with PGP key
  bool encrypted = 18;

  // Should be a valid Cron expression
  // based on https://en.wikipedia.org/wiki/Cron
  string cron = 19;
  // Timezone to be used with the cron,
  // if left blank it will default to the
  // local time of whatever server it is on.
  // e.g. "America/Denver", "America/New_York"
  // Must exist in TZ database
  // https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
  string timezone = 20;
  // Name of the transfer_config, used to find sftp configuration
  string transfer_config_name = 21;
}

message RndEnrichmentProcess {
  string org_id = 1;
  string field = 2;
  string date_last_contact_field = 3;
}

message CjsImportProcess {
  // Specifies which CJS List to import from
  string cjs_collection_id = 3;
  // Enable/Disable the process
  bool enabled = 5;

  // Should be a valid Cron expression
  // based on https://en.wikipedia.org/wiki/Cron
  string cron = 6;
  // Timezone to be used with the cron,
  // if left blank it will default to the
  // local time of whatever server it is on.
  // e.g. "America/Denver", "America/New_York"
  // Must exist in TZ database
  // https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
  string timezone = 7;
  // Specifies if a dedup should be performed when importing
  bool dedup = 8;
}

message CjsExportProcess {
  // If creating a new list, generate
  // a random UUID for `cjs_collection_id`
  string cjs_collection_id = 3;
  // Specifies which fields should be exported
  ExportHeader header = 4;
  // To Disable, or run as a test
  api.commons.RunType run_type = 5;
  // `list_name` and `key_field` are only needed
  // when creating a new list, they will
  // be ignored otherwise

  // Specifies the name of the CJS list
  // to be created
  string cjs_collection_name = 6;
  // If true it will overwrite the current
  // collection instead of appending
  bool overwrite = 8;
  // If true the collection will update existing
  // entries matched with the key field
  bool update = 9;
  // Field to use for updating
  string update_key_field = 10;
}

message CjsEnrichmentProcess {
  // Specifies the Journey collection to be used
  // Available options can be obtained
  // from Journey
  string cjs_collection_id = 3;
  // Specifies the LMS list field
  // to be used as the key when
  // doing search in CJS list
  string key_field = 4;
  // Specifies how to enrich the LMS list
  // OR - Acjs all records, merging any matches
  // XOR - Keep records that are only in one of the lists (exclude those in both)
  // AND - Keep only records that are in both lists, merge the records
  // JOIN - Keep all of the primary source and merge in matches from the
  //        secondary source
  api.commons.EnrichmentType enrich_type = 5;
  // Specifies the primary list (LMS or CJS)
  // When merging records, all the fields from the primary
  // source will be used, and only the extra fields (if any)
  // will be added to the record
  api.commons.PrimarySource primary_source = 6;
  // Specifies the Journey collection field
  // to be matched against.
  // Available options can be obtained
  // from Journey
  string cjs_key_field_name = 7;
  // Specifies if the primary list columns
  // should be overwritten by the secondary
  // on matching column names
  bool column_overwrite = 8;
  // Specifies what to do when there
  // is a duplicate match for the key in the collection
  api.commons.DedupKeyPolicy dedup_key_policy = 9;
}

// this process downloads the records from the signed_url
// and writes them to the output
message AppendProcess {
  string fts_id = 5;
}

// USE INSTEAD of ComplProcess
message LookupProcess {
  message ComplProcess {
    string country_code = 11;
  }
  message ListLookup {
    string org_id = 1;
    string region_id = 2;
    string element_id = 3;
    // latest list will be used by default
    int64 version = 4;
  }
  message UrlLookup {
    string url = 5;
    // the template file used to convert records to proto
    // if left blank it assumes already converted format
    FileTemplate file_template = 10;
  }

  // names of the fields that will be used in the lookup
  repeated string field_names = 6;
  oneof proc {
    // lookup from compliance
    ComplProcess compl = 7;
    // lookup from another version of another list
    ListLookup list = 8;
    // lookup against the records at the url
    UrlLookup url = 9;
  }
}

// DEPRECATED
message ComplProcess {}

message CFSExportConfig {
  api.commons.ExportType type = 1;
  string value = 2;
}

message CFSExportReqHeader {
  ExportHeader export_header = 1;
  repeated CFSExportConfig configs = 2;
  string org_id = 3;
  string region_id = 4;
}

message CFSExportProcess {
  ExportHeader export_header = 1;
  repeated CFSExportConfig configs = 2;
}

message FilterProcess {
  string expression = 1;
  repeated FilterOperation operations = 2;
  bool negate = 3;
}

message FilterOperation {
  // sequence of checks taken on a record that all must reduce to a boolean.
  // All results are then either AND-ed or OR-ed together. The resulting bool is
  // returned.
  repeated FilterCheck checks = 1;
  api.commons.ChainOperator operator = 2;
}

// Describes a lookup of a field on a record, checking its value or type against
// another value. Each FilterCheck must boil down to a bool value.
message FilterCheck {
  // a value to compare against.
  message Value {
    oneof val {
      // compare against the provided static string
      string string_val = 1;
      // compare against the provided static double
      double number_val = 2;
      bool bool_val = 3;
      // compare against the value looked up from the record by field_name
      FieldIndex field_name = 5;
      // compare against the datetime value
      DateTime date_time = 14;
    }
  }
  // A bool comparison of a field vs some other value
  message ValueComparison {
    // name of the field to lookup in record. This field's value will be used
    FieldIndex field_name = 6;
    // operation we are performing
    api.commons.CompareOperator op = 7;
    // other value to compare against
    Value value = 8;
    // if "negate" is true, we negate the result of this comparison
    bool negate = 9;
    // if "exists" is true, we check for field existence
    bool exists = 10;
  }
  // bool comparison saying the field matches a specific type or not
  message TypeComparison {
    // name of the field to lookup in record. This field's type will be used
    FieldIndex field_name = 9;
    // the type we must match to report true
    api.commons.RecordType matches_field_type = 10;
    // if "negate" is true, we negate the result of this comparison
    bool negate = 11;
  }
  // list comparison of a list of fields vs list of values
  message ListComparison {
    // name of the field to lookup in record. This field's value will be used
    FieldIndex field_name = 5;
    message FieldOrVal {
      oneof val {
        FieldIndex field = 6;
        Value value = 7;
      }
    }
    repeated FieldOrVal data = 8;
    // if "negate" is true, we negate the result of this comparison
    bool negate = 9;
  }
  // We can either check value, or type in one step, not both.
  oneof check {
    ValueComparison val_comp = 12;
    TypeComparison type_comp = 13;
    ListComparison list_comp = 14;
  }
}

message GSExportProcess {
  string bucket = 2;
  string file = 3;
}

message P3ExportProcess {
  // Specifies which fields to export
  ExportHeader header = 1;
  string contact_list_prefix = 2;

  // P3 API Username
  string username = 3;
  // P3 API Password
  string password = 4;
  // Call List Country
  string country = 5;
  // Specifies how to handle duplicate phone numbers.
  // 'Keep and Discard' = keep the record, discard the number.
  // 'Allow' = keep the record & number.
  // 'Discard' = discard both.
  // 'Duplicate List' = create duplicate list
  // Default = 'Keep and Discard'
  api.commons.DuplicatePolicyType dupe_policy = 6;
  // Specifies how records without numbers should be handled.
  api.commons.AbsentPolicyType absent_policy = 7;
  /// The number of the import template describing this import.
  int32 template_id = 8;
  // Specifies a default area code to use with file
  int32 default_area_code = 9;
  // The number of the template describing the campaign to be sent.
  int32 schedule_template_number = 10;

  // `description` will be deprecated in
  // favor of `file_pattern`,
  // currently it is ignored
  string description = 11;

  // To Disable or run as test
  api.commons.RunType run_type = 12;
  // `file_pattern` is what sets the description
  // we are using api.commons.FilePattern so that it
  // can change depending on the day.
  // The directory field in this `file_pattern`
  // should not be used (it will be ignored)
  api.commons.FilePattern file_pattern = 13 [deprecated = true];
  // what to name the file
  api.commons.ConstructedFilename filename = 43;

  // Advanced options
  // Allows ids to be specificied in place of the ones
  // already specified into the schedule template
  repeated int64 caller_ids = 14;
  // Scrub known cell numbers from call list
  bool cell_scrub = 15;
  // Campaign start time
  google.protobuf.Timestamp start_time = 16;
  // Campaign end time
  google.protobuf.Timestamp end_time = 17;
  // FIRST, NATURAL, or CUSTOM. Will default to FIRST
  api.commons.DialOrderType dial_order = 18;
  // TCN P3 will use the custom calling rules defined in the account.
  // If client preference is set for custom calling rules they will be used.
  // Default = 'false'
  reserved 19; // use_custom_calling_rules
  // Identifies the Email column in the contact list.
  string email_field = 20;
  // Email address to send campaign from.
  string email_from = 21;
  // Dial numbers from east to west.
  // 'true' = numbers will be dialed from east to west.
  // 'false' = numbers will be dialed in default order.
  // Default = 'false'
  bool follow_the_sun = 22;
  // Messages Per Minute
  int32 messages_per_minute = 23;
  // Allow contacts to be inserted in random order.
  bool randomize_contacts = 24;
  // Specifies if to schedule as paused.
  bool schedule_as_paused = 25;
  // Allows selection of a schedule rule (input by name)
  string schedule_rule = 26;
  // TCN P3 will attempt to very file uniqueness over a 20 hour period.
  // If duplicates are found the duplicates are failed.
  // 'true' = do not attempt to verify file uniqueness.
  // 'false' = attempt to verify file uniqueness.
  // Default = 'false'
  bool sha_digest_override = 27;
  // Identifies the Cell Phone column in the contact list.
  string sms_field = 28;
  // Number to to send campaign from.
  int64 sms_source_number = 29;
  //  Allow calls after hours.
  // 'true' = calls may go out after 9 P.M. and before 8 A.M.
  // 'false = calls will not go out after 9 P.M. and before 8 A.M.
  // Default = 'false'
  bool timezone_override = 30;
  // Specifies how to handle zip code scrubbing.
  // If client preference is set to use zip code scrub, that value will be default.
  // 'true' = will scrub based on the client preference for zip code fields.
  // 'false' = will not scrub based on zip code.
  // Default = 'false'
  bool zip_scrub = 31;
  // Specifies the completion percentage at which to execute campaign linking.
  int32 completion_threshold = 32;
  // TIMEZONE must exist in the TZ database:
  // http://en.wikipedia.org/wiki/List_of_tz_database_time_zones
  string timezone = 33;
  // Specifies the Natural Language Compliance Rule
  // to be used. Empty will not use NLC
  string compliance_rule = 34;

  // what separates a field from another.  In csv this is ','
  string field_delimiter = 35;
  // what separates a record from another. In csv this is '\n'
  string record_delimiter = 36;
  // Wrap fields with `"`
  bool quote_fields = 37;
  // Specifies whether to export using the date
  // format defined by the field in the file
  // template or use the default
  bool use_custom_date_format = 38;
  // Specifies the export filetype
  // (CSV, CUSTOM, TSV, etc.)
  // If the export filetype is anything other than custom
  // `field_delimiter`, `record_delimiter` and `quote_fields`
  // will be ignored
  api.commons.FileFormat file_format = 39;
  // The fields `days_into_future`, `start_hour`
  // and `end_hour`
  // will override `start_time`, `end_time`
  // and should be used over `start_time`, and `end_time`
  // Specifies how many days into the future to schedule
  // 0 <= days < 7, 0 = today, 1 = tomorrow, etc.
  int64 days_into_future = 40;
  // Specifies the time to start
  // in format "15:04"
  string start_hour = 41;
  // Specifies the time to end
  // in format "15:04"
  string end_hour = 42;
  // will schedule the campaign by timezone
  bool schedule_by_timezone = 44;
  // If true, it will try to bunch all phone number
  // fields to the left.
  bool shift_phone_fields = 45;
  // campaign linking
  bool do_campaign_linking = 46;
  string campaign_link_id = 47;
  string stop_trigger = 48;
}

// Describes an export process to compliance list/DNCL
// Expiration is optional
// CountryCode is required only if the field type is phone/sms
message ComplianceExportProcess {
  string list_name = 2;
  string field = 3;
  string expiration_field = 4; // Optional, has to be type date
  string country_code = 5; // Optional, only needed with phone/sms
  api.commons.RunType run_type = 6;
  api.commons.ComplianceListType compliance_list_type = 7;
}

message ScrubProcess {
  string list_id = 3;
  string field = 4;
}

// This process collects data from a specific fields in all the records in the lms list
// and calls Compliance.DeleteScrubListEntries() on them.
message DeleteScrubEntriesProcess {
  // 'list_id' is the id of the scrub list in compliance to delete from
  string list_id = 3;
  // 'field' is which column on an lms record that contains the data we want to delete
  // from the scrub list in compliance.
  // ex: if field is "first"  all records that contain a record field named "first" will have their contents
  // collected, and sent to compliance to be deleted from scrub list.
  string field = 4;
}

message FrequencyProcess {
  // LMS field from the list to be used
  string field = 4;
  // Duration to check frequency
  int64 days = 5;
  // Country code needed if `field` is a phone number
  string country_code = 6;
  // Field we are checking against in frequency
  // e.g. Account Number
  // Will default to "phone_number"
  string meta_field = 7;
  // Option for dispositions given in key
  // value pairs. Value is optional, it will
  // just check for existence of key if left out.
  repeated DispositionPair dispositions = 8;
  // Different result types
  // e.g. Answered,Answered Machine,Busy, etc.
  repeated string results = 9;
  // Options for dispositions given in key/value
  // pair sets. Values are optional. Must have
  // at least one match in each set.
  repeated DispositionSet disposition_sets = 10;
}

message DispositionSet {
  // A set of disposition pairs.
  repeated DispositionPair dispositions = 1;
}

message DispositionPair {
  string key = 1;
  // Value is optional.
  // If left blank, we will just
  // check for existence of `key`.
  string value = 2;
}

message SftpExportProcess {
  // where we try and write the data to on the destination filesystem
  string dest_filepath = 1; // DEPRECATED!!
  // if left "", the service will attempt to use a public key instead
  string password = 2; // DEPRECATED
  // where we are trying to connect to.
  string address = 3;
  // username for sftp connection
  string username = 4; // DEPRECATED
  // port we will attempt to establish a connection with
  int32 port = 5;

  // File format to use (CSV, CUSTOM, TSV, etc.)
  // `field_delimiter`, `record_dilimiter`, and `quote_fields`
  // will be ignored the the format is not CUSTOM
  api.commons.FileFormat fileformat = 7;

  // Specifies whether to use headers in the
  // export file or not.
  bool prepend_headers = 8;
  // Specifies custom field delimiter (default `,`)
  string field_delimiter = 9;
  // Specifies custom record delimiter (default `\n`)
  string record_delimiter = 10;

  // Specifies the construction of the export filename
  api.commons.FilePattern file_pattern = 11 [deprecated = true];
  // Run type can be RUN (default), TEST, or DISABLED
  api.commons.RunType run_type = 12;

  // Specifies which fields to export
  ExportHeader header = 13;
  // Wrap fields with `"`
  bool quote_fields = 14;
  // Specifies whether to export using the date
  // format defined by the field in the file
  // template or use the default
  bool use_custom_date_format = 15;

  // directory to put the file in
  string directory = 16;
  // what to name the file
  api.commons.ConstructedFilename filename = 17;
  // If true, it will try to bunch all phone number
  // fields to the left.
  bool shift_phone_fields = 18;
  // transfer configs will be unique by name, transfer configs store credential data
  string transfer_config_name = 19;
}

message WfmMultiSkill {}
message WfmExportProcess {
  // single_skill import with this sid in the data
  // multi_skill wfm will fetch the data from
  // the 'Skill Profile' column
  oneof skill_profile {
    int64 single = 1;
    WfmMultiSkill multi = 2;
  }
}
message ExportHeader {
  repeated string names = 1;
}

message SortReq {
  oneof request {
    // the header, this will always be sent as the first message, and only
    // records will be sent after that.
    SortCriteria criteria = 1;
    RecordProto record = 2;
  }
}

message CFSExportReq {
  oneof request {
    CFSExportReqHeader header = 1;
    RecordProto record = 2;
  }
}
message DeDupCriteria {
  api.commons.DeDupActions action = 3;
  repeated FieldIndex fields = 2;
}

message SortCriteria {
  // The ordering, ascending or descending
  repeated api.commons.SortOrder ordering = 1;
  repeated FieldIndex field_order = 2;
}

message Error {
  string error = 1;
  string raw_value = 2;
}

message RecordFieldMap {
  map<string, RecordFieldProto> fields = 1;
}

message Currency {
  string symbol = 1;
  string raw_value = 2;
  double value = 3;
  string name = 4;
  bool invalid = 5;
}
message Phone {
  string raw_value = 3;
  string full_number = 4;
  bool invalid = 5;
}
message PostalCode {
  string postal_code = 1;
  bool invalid = 2;
}

message Email {
  string local_part = 1;
  string domain = 2;
  string full_address = 3;
  bool invalid = 4;
}

// modifies a DateTime by specific amount
message DateTimeModifier {
  int32 years = 1;
  int32 weeks = 3;
  int32 days = 4;
  int32 hours = 5;
  int32 minutes = 6;
  int32 seconds = 7;
}

message DateTime {
  // the raw string given when parsing the datetime obj
  string raw_value = 1;
  // the format string used to create this datetime object
  string format = 2;
  // our date value ordered from most specific to least
  api.commons.DateTimePrecision precision = 3;
  // modifier to apply to our value when comparing
  DateTimeModifier modifier = 11;
}
message EnrichedPhone {
  string area_code = 1;
  string block_id = 2;
  string carrier = 3;
  string cc = 4;
  string ccnsn = 5;
  string cell_prefix = 6;
  string city = 7;
  string coc_type = 8;
  bool dst = 9;
  string international_prefix = 10;
  string iso2 = 11;
  string language = 12;
  //Location location = 13;
  string max = 14;
  string min = 15;
  string national_prefix = 16;
  string ndc = 17;
  string prefix = 18;
  string region_code = 19;
  string region_name = 20;
  string ssc1 = 21;
  string ssc2 = 22;
  string ssc3 = 23;
  string ssc4 = 24;
  string source = 25;
  string time_zone = 26;
  string type = 27;
  bool uses_ndc = 28;
  float utc = 29;
  //RecordFieldProto enriched_from = 30;
}

message EnrichedZip {
  int32 accuracy = 1;
  string admin_code1 = 2;
  string admin_code2 = 3;
  string admin_code3 = 4;
  string admin_name1 = 5;
  string admin_name2 = 6;
  string admin_name3 = 7;
  string area_code = 8;
  string city_name = 9;
  string city_type = 10;
  string country_code = 11;
  string county_fips = 12;
  string county_name = 13;
  bool dst = 14;
  string iso2 = 15;
  //Location location = 16;
  string msa_code = 17;
  string place_name = 18;
  string postal_code = 19;
  string postal_code_key = 20;
  string postal_type = 21;
  string province_abbr = 22;
  string province_name = 23;
  string source = 24;
  string state_fips = 25;
  string time_zone = 26;
  float utc = 27;
  //RecordFieldProto enriched_from = 28;
}

// represents need for getting current timestamp during processing
message Now {}

// a specific point in time, down to second presision.
message Timestamp {
  int32 year = 3;
  // januaury = 1, december = 12
  int32 month = 4;
  // between 1-53
  int32 week = 5;
  // depending on the month 1-31
  int32 day_of_month = 6;
  // 0-6 sunday = 0
  int32 day_of_week = 7;
  // 1 - 366 (leap year)
  int32 day_of_year = 8;
  // 0-23
  int32 hour = 9;
  // 0-59
  int32 minute = 10;
  // 0-59
  int32 second = 11;
}

// a specific year, month, and day.
message Date {
  int32 year = 3;
  int32 month = 4;
  int32 week = 5;
  int32 day_of_month = 6;
  int32 day_of_week = 7;
  int32 day_of_year = 8;
}

// a specific month and day of the year
message MonthAndDay {
  int32 month = 3;
  int32 week = 4;
  int32 day_of_month = 5;
  int32 day_of_week = 6;
  int32 day_of_year = 7;
}

// a specific day of the week.  sunday = 0
message DayOfWeek {
  int32 day_of_week = 3;
}

// a specific time of day. 24 hour format. 12:00:00AM = 0,0,0
message TimeOfDay {
  int32 hour = 3;
  int32 minute = 4;
  int32 second = 5;
}

message FileFormatParams {
  // use skip_first_lines
  int32 skip_first_no_lines = 10 [deprecated = true];
  string skip_lines_match_regex = 11 [deprecated = true];
  bool trim_spaces = 12;
  string custom_delimiter = 13;
  bool skip_first_line = 14;
  // for json file formats:
  // if non-empty represents that the file is one large json object,
  // and that this is the json path to the root that contains all the records.
  // example: { response: { records: [...] } }
  // to get to the records stored at [...], we would use
  // json_dot_path="response.records"
  // If left blank, we are expected each json object to be on its own line: (jsonl)
  string json_dot_path = 15;
}
message ReshapeProcess {
  repeated ReshapeAction actions = 1;
}

message ReshapeAction {
  // rename this field's name to new_name, keep the value the same
  message Rename { // legal: All
    string new_name = 10;
  }
  // add a static value to field's current value.
  message AddValue { // legal: numbers, currency, timestamp, time, date
    // if the field type is time-like, this is number of seconds
    double value = 11;
  }
  // add or subtract a datetime modifier to the field
  message AddDate {
    DateTimeModifier datetime = 45;
  }
  // add two fields values together. If field is time-like, other_field must be
  // either number or timestamp
  message AddField { // legal: numbers, currency, timestamp, time, date
    FieldIndex other_field = 12;
  }
  // subtract a static value to field's current value
  message SubtractValue { // legal: numbers, currency, timestamp, time, date
    // if the field type is time-like, this is number of seconds
    double value = 11;
  }
  // subtract two fields values. If field is time-like, other_field must be
  // either number or timestamp
  message SubtractField { // legal: numbers, currency, timestamp, time, date
    FieldIndex other_field = 12;
  }
  // convert a field to another type, if conversion fails, it will be an error
  // type
  message Convert {
    api.commons.RecordType newType = 17;
  }
  // will remove "field" from the record
  message RemoveField {}
  // will add "field" to the record with default starting value
  // TODO: make a RecordFieldProtoValue, it is a noeof
  message AddNewField {
    RecordFieldProto starting_value = 18;
  }

  // will add "field" to the record with default starting value from other field
  message AddNewFieldFromField {
    string name = 10;
    FieldIndex other_field = 12;
  }
  // change the currency value to one represented
  message ChangeCurrencyType { // legal: Currency
  }
  // will set field with the value
  message SetFieldValue {
    RecordFieldProto value = 18;
  }

  // will set "field" from other field
  message SetFieldFromField {
    string name = 10;
    FieldIndex other_field = 12;
  }

  // merges together all the strings fetched from FieldOrVal into the reshape
  // action field. overrides any data already in the field.
  message Merge { // Legal: StringValue
    message FieldOrVal {
      oneof val {
        FieldIndex field = 38; // fetch the string from this field
        string value = 43; // use this exact string value
      }
    }
    repeated FieldOrVal data = 44;
  }
  // provide padding to the right or left of the string field
  message Pad {
    // what character to pad with.  Must be length 1.
    string char = 10;
    // what the desired length of the string is.
    // if < 0 we will use the len of the longest string in the column
    int32 amount = 12;
    // prefixorsuffix
    bool prefix = 13;
  }

  //trims off specific characters from a prefix or suffix.
  //Or can trim off a certain amount of characters from the left or right.
  message Trim {
    oneof opt {
      // trim this exact amount of chars. If the string is less than amount in length
      // the string is set to the empty string
      // examples:
      // - trim.amount = 3 on 'abcdef' => 'def'
      // - trim.amount = 3 on 'ab' => ''
      int32 amount = 1;
      // trim this specific string from the field if it exists, otherwise do nothing
      // examples:
      // - trim.data = 'abc' on 'abcdef' => 'def'
      // - trim.data = 'abc' on 'ab' => 'ab'
      string data = 2;
      // trim til this specific marker. If marker doesn't exist string is left alone
      // examples:
      // - trim.marker = 'de' on 'abcdef' = 'def'
      string marker = 3;
    }
    // if true, the trim operation starts at the end of the string and works backwards
    bool suffix = 10;
  }

  // extract takes a string and can take any combination of substrings of the string
  message Extract {
    // represents an index. can be a string or a number
    message Index {
      oneof val {
        // the base 0 index of the string
        int32 position = 12;
        // an index matching the substring. Starting at the beginning of the substring
        string match = 43;
      }
    }
    // Slice represents a part of a string. think of a python or golang slice operator
    // where the new substring starts at the starting index and ends at the ending index exclusively
    message Slice {
      // the default inclusivity is [start, end)
      // this marks whether to not include the start_index marker in the slice
      bool start_is_exclusive = 13;
      // this marks whether to include the end_index marker in the slice
      bool end_is_inclusive = 14;
      // start index marks where to start the slice at. can be a string or number
      // subsequent indexes are backup indexes incase the first doesn't exist
      repeated Index start_index = 35;
      // end index marks where to start the slice at. can be a string or number
      // subsequent indexes are backup indexes incase the first doesn't exist
      repeated Index end_index = 36;
    }
    // parts represents several substrings using indices
    repeated Slice parts = 39;
  }

  // NOT a FieldIndex
  string field = 19;
  // will only execute on the matching type (defaults to ALL)
  api.commons.RecordType matching_type = 20 [deprecated = true];
  FilterCheck predicate = 50;
  oneof action {
    Rename rename = 22;
    AddValue add_value = 23;
    AddField add_field = 24;
    AddDate add_date = 47;
    SubtractValue subtract_value = 25;
    SubtractField subtract_field = 26;
    Convert convert = 28;
    RemoveField remove_field = 29;
    AddNewField add_new_field = 30;
    ChangeCurrencyType change_currency_type = 31;
    Merge merge = 40;
    SetFieldValue set_field_value = 41;
    AddNewFieldFromField add_new_field_from_field = 45;
    SetFieldFromField set_field_from_field = 46;
    Pad pad = 52;
    Trim trim = 53;
    Extract extract = 54;
  }
}

// stored as json in lms_history table
message ListMetrics {
  // signifies how many records existed at the beginning of the operation
  int32 input_record_count = 1;
  // how many records existed on the element at the end of the operation
  int32 output_record_count = 2;
  // all the field names that exist in the list
  repeated string field_names = 3;
  // all the field types that exist. field_types[i] has a name of field_names[i].
  // THeir indexes match up
  repeated api.commons.RecordType field_types = 4 [deprecated = true];
  repeated api.commons.FieldType ftypes = 18;
  // the counts of the field_name[i], field_type[i] pairs.
  // ex: if field_name[i] == 'test' and field_types[i] == record_type_err, and field_counts[i] == 10
  // means we woud have 10 fiels named test that were error types in the list.
  repeated int32 field_counts = 5;
  // the run type for the exchange.  Will only mean anything if the element is an exchange.
  api.commons.RunType run_type = 6;
  // will contain the http post response body from the POST request to p3 backoffice
  // only relevent on p3 exchange elements.
  string success_message = 7;
  // specifies the number of fields the largest record had in the list.
  // ex: max_record_width of 10 means that there exists at least 1 record in the list had 10 fields.
  // meta fields (fields that start with an '_') are not counted
  int32 max_record_width = 8;
  // opposite of max_record_width
  int32 min_record_width = 9;
  // the first index we can find the record with max_record_width fields
  int32 max_record_index = 10;
  // the first index we can find the record with min_record_width fields
  int32 min_record_index = 11;
  // the upstream files that were used to process this element.
  // usually this field will either be empty, or have 1 item in it.
  repeated string files = 12;
  // which groups exist in the list.
  // a group is a tagged record with a field '_group' and a string payload
  repeated string groups = 13;
  // represents which fields were looked up, but were missing from the record
  // this is the set of all missing fields
  repeated string missing_fields = 15;
  // represents how many seconds it took for the event to start getting worked on
  double seconds_to_start = 16;
  // represents how mahy seconds it took to process the event
  double seconds_to_process = 17;
}

message ParseReq {
  // if empty, we will use GetAvailableFields instead of
  // ListAvailableFieldsByElementId
  string element_id = 3;
  // if empty, a new session will be returned with the response
  string session_id = 4;
  // current expression string, can be empty
  string expression = 5;
}

message ParseRes {
  // the session_id should be returned on future requests to make things faster
  string session_id = 1;
  string expression = 2;
  // a list of valid tokens we can use at this point
  repeated string next_tokens = 3;
  // if not a valid expression, error should have the message why
  string error = 5;
  // whether the result_expression is complete
  bool complete = 6;
  // if complete is true, process will have a completed Process defined.
  // if complete is true, you will be able to send process to lms_api through
  // CreatePipelineElement.
  Process process = 7;
}

message Event {
  // pk
  int64 event_id = 3;
  // element_id that created this event (nil if its an upload, or sftp_import)
  google.protobuf.StringValue parent_id = 5;
  // other inputs to this event
  api.commons.StringArraySql input_ids = 6;
  string element_id = 7;

  Process process = 9;
  // when this event got to the database
  google.protobuf.Timestamp upload_ts = 10;
  // when the scheduler started processing (could be nil if not started)
  google.protobuf.Timestamp started_ts = 11;
  // processing finished (could be nil if not finished)
  google.protobuf.Timestamp finished_ts = 12;
  // (not used yet, so always nil) event wont be attempted till after this time
  google.protobuf.Timestamp backoff_till = 13;
  // how many attempts this event is taking
  int32 attempts = 14;

  // which hisotry record this event maps to. (only populated if finished_ts is
  // not nil)
  google.protobuf.Int64Value latest_history = 15;
}
message Events {
  repeated Event events = 1;
}

message ViewQueueReq {
  // return events with upload_ts times newer than this timestamp
  google.protobuf.Timestamp newer_than = 1;
  // do not return events with upload_ts times newer than this timestamp
  google.protobuf.Timestamp no_newer_than = 2;
  // skip records with event_id smaller than this id
  int64 after_event_id = 3;
  // max number of records to retrieve
  int64 number_of_records = 4;
}

message CollectionMetadata {
  // Name and ID of the collection
  string collection_id = 3;
  string collection_name = 4;
  // Describes the fields used by the collection
  repeated CollectionFieldMetadata fields = 5;
  bool deleted = 6;
  string created_by = 7;
  google.protobuf.Timestamp created_on = 8;
  google.protobuf.Timestamp last_queried = 9;
  int64 query_count = 10;
  int64 entry_count = 11;
  google.protobuf.Timestamp last_updated = 12;
  int64 search_count = 13;
  google.protobuf.Timestamp last_searched = 14;
}

message CollectionEntry {
  string collection_id = 3;
  string entry_id = 4;
  repeated CollectionField fields = 5;
  google.protobuf.Timestamp last_updated = 6;
}

message MatchReq {
  string collection_id = 3;
  repeated CollectionField fields = 4;
  int64 batch_size = 5;
}
message MatchRes {
  repeated CollectionEntry entries = 1;
}

// Metadata associated with a field
message CollectionFieldMetadata {
  string field_name = 1;
  api.commons.FieldType field_type = 2;
  // Optional field
  // Specifies formating for the field
  // e.g. for a datetime it might be
  // something like "MM/DD/YYYY hh:mm:ss"
  string field_format = 3;
}

message CollectionField {
  string field_name = 1;
  string field_value = 2;
}

message GetCollectionReq {
  string collection_id = 3;
}

message StreamCollectionReq {
  string collection_id = 3;
}

message DeleteCollectionReq {
  string collection_id = 3;
}

message ResetCollectionReq {
  string collection_id = 3;
}

message ListCollectionsReq {}

message ListCollectionsRes {
  repeated CollectionMetadata collections = 1;
}

message SearchCollectionsPaginatedReq {
  // Specifies which collections we are searching in
  // If empty it will search all collections.
  repeated string collection_ids = 3;
  // Specifies what we are searching for
  Search search = 4;
  // Specifies where to start in the results
  int64 from = 5;
  // How many results to include in a page
  int64 page_size = 6;
}

message Search {
  // The term we are searching for
  string term = 1;
  // Sets the amount of fuzziness allowed
  // in matches
  // Example:
  // Searching "term" would also match "temr"
  // Not compatible with a substring match
  int64 fuzziness = 2;
  // Checks if a subset of the content matches
  // Example:
  // Searching "but" would also match "rebuttal"
  // Not compatible with fuzziness (will override fuzziness)
  bool substring = 3;
  // Specifies if the search should be negated
  // Example:
  // Searching "term" would match everything NOT including "term"
  bool negate = 4;
  // Specifies if we should be case sensitive
  bool case_sensitive = 5;
}

message PaginatedSearchRes {
  // A page of results
  repeated CollectionEntry entries = 1;
  // Specifies the total number of results
  int64 total = 2;
}

message GetCollectionEntriesReq {
  string collection_id = 3;
  int64 from = 4;
  int64 page_size = 5;
  string search_after_id = 6;
}

message GetCollectionEntriesRes {
  CollectionMetadata metadata = 1;
  repeated CollectionEntry entries = 2;
}

message DeleteCollectionEntryReq {
  string collection_id = 3;
  string entry_id = 4;
}

message ListCampaignLinksRes {
  repeated Link Links = 1;
}

message Link {
  int64 xml_client_prop_sid = 1;
  string name = 2;
  string description = 3;
}

message CjsSearchField {
  string cjs_search_field_id = 1;
  string cjs_search_definition_id = 2;
  string field_name = 3;
  api.commons.FieldType field_type = 4;
  string field_value = 5; // leave empty in definition to prompt user for value
}

message CjsSearchDefinitionMetadata {
  string cjs_search_definition_id = 1;
  string name = 4;
  string description = 5;
  bool deleted = 6;
  int64 exec_count = 7;
  int64 exec_success = 8;
  int64 exec_fail = 9;
  google.protobuf.Timestamp created_date = 10;
  google.protobuf.Timestamp last_edited = 11;
}

message CjsSearchDefinition {
  CjsSearchDefinitionMetadata metadata = 1;
  repeated CjsSearchField search_fields = 2;
  repeated CjsSearchField whitelisted_return_fields = 3;
  repeated CjsSearchField blacklisted_return_fields = 4;
  // field(s) used to identify a unique individual within a collection (ex. account_number)
  repeated CjsSearchField unique_identifiers = 5;
}

message GetCjsSearchDefinitionReq {
  string cjs_search_definition_id = 1;
}

message DeleteCjsSearchDefinitionReq {
  string cjs_search_definition_id = 1;
}

message ListCjsSearchDefinitionsReq {}

message ListCjsSearchDefinitionsRes {
  repeated CjsSearchDefinitionMetadata definitions = 1;
}

message ExecuteCjsSearchDefinitionReq {
  string search_definition_id = 1;
  repeated CjsExecuteSearchField search_fields = 4;
}

message ExecuteCjsSearchDefinitionRes {
  repeated CollectionEntries collection_entries = 1;
}

message CollectionEntries {
  CollectionMetadata metadata = 1;
  repeated CollectionEntry entries = 2;
}

message CjsExecuteSearchField {
  oneof field {
    string field_name = 1;
    api.commons.FieldType field_type = 2;
  }

  string field_value = 3;
}

message CjsSecureSearchCriteriaMetadata {
  string cjs_secure_search_criteria_id = 1;
  bool deleted = 4;

  // auditing
  google.protobuf.Timestamp created_on = 10;
  google.protobuf.Timestamp last_updated = 11;
}

message CjsSecureSearchCriteria {
  CjsSecureSearchCriteriaMetadata metadata = 1;
  repeated CjsSecureSearchCriteriaField fields = 2;
}

message GetCjsSecureSearchCriteriaReq {}

message CjsSecureSearchCriteriaField {
  string cjs_secure_search_criteria_field_id = 1;
  string cjs_secure_search_criteria_id = 2;
  api.commons.FieldType field_type = 3;
}

message SplitCriteria {
  oneof action {
    SplitByUnique unique = 1;
    SplitByMaxSize max_size = 2;
    SplitByEqualParts equal_parts = 3;
  }
}

message UniquePair {
  FieldIndex split_on_fields = 1;
  string split_value = 2;
}

message SplitByNamedUnique {
  repeated UniquePair named_fields = 1;
}

message SplitByUnique {
  repeated FieldIndex split_on_fields = 1;
}

message SplitByMaxSize {
  int32 max_size = 1;
}

message SplitByEqualParts {
  int32 part_size = 1;
}
